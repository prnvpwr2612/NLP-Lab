{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\ppawa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getwordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def morphological_analysis(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    analyzed_words = []\n",
    "    for token, pos_tag in pos_tags:\n",
    "        wordnet_pos = getwordnet_pos(pos_tag)\n",
    "        if wordnet_pos:\n",
    "            lemma = lemmatizer.lemmatize(token, pos=wordnet_pos)\n",
    "            analyzed_words.append((token, pos_tag, lemma))\n",
    "        else:\n",
    "            analyzed_words.append((token, pos_tag, token))\n",
    "    return analyzed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = '''During the Renaissance, art and architecture were revolutionized by the emergence of humanism. \n",
    "Artists such as Leonardo da Vinci and Michelangelo created iconic works that showcased their mastery of technique and innovative use of perspective. \n",
    "The Renaissance saw a resurgence of interest in classical Greek and Roman art, leading to the development of new styles and techniques.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: During, POS Tag: IN, Lemma: During\n",
      "Token: the, POS Tag: DT, Lemma: the\n",
      "Token: Renaissance, POS Tag: NNP, Lemma: Renaissance\n",
      "Token: ,, POS Tag: ,, Lemma: ,\n",
      "Token: art, POS Tag: NN, Lemma: art\n",
      "Token: and, POS Tag: CC, Lemma: and\n",
      "Token: architecture, POS Tag: NN, Lemma: architecture\n",
      "Token: were, POS Tag: VBD, Lemma: be\n",
      "Token: revolutionized, POS Tag: VBN, Lemma: revolutionize\n",
      "Token: by, POS Tag: IN, Lemma: by\n",
      "Token: the, POS Tag: DT, Lemma: the\n",
      "Token: emergence, POS Tag: NN, Lemma: emergence\n",
      "Token: of, POS Tag: IN, Lemma: of\n",
      "Token: humanism, POS Tag: NN, Lemma: humanism\n",
      "Token: ., POS Tag: ., Lemma: .\n",
      "Token: Artists, POS Tag: NNS, Lemma: Artists\n",
      "Token: such, POS Tag: JJ, Lemma: such\n",
      "Token: as, POS Tag: IN, Lemma: as\n",
      "Token: Leonardo, POS Tag: NNP, Lemma: Leonardo\n",
      "Token: da, POS Tag: NN, Lemma: da\n",
      "Token: Vinci, POS Tag: NNP, Lemma: Vinci\n",
      "Token: and, POS Tag: CC, Lemma: and\n",
      "Token: Michelangelo, POS Tag: NNP, Lemma: Michelangelo\n",
      "Token: created, POS Tag: VBD, Lemma: create\n",
      "Token: iconic, POS Tag: JJ, Lemma: iconic\n",
      "Token: works, POS Tag: NNS, Lemma: work\n",
      "Token: that, POS Tag: WDT, Lemma: that\n",
      "Token: showcased, POS Tag: VBD, Lemma: showcased\n",
      "Token: their, POS Tag: PRP$, Lemma: their\n",
      "Token: mastery, POS Tag: NN, Lemma: mastery\n",
      "Token: of, POS Tag: IN, Lemma: of\n",
      "Token: technique, POS Tag: NN, Lemma: technique\n",
      "Token: and, POS Tag: CC, Lemma: and\n",
      "Token: innovative, POS Tag: JJ, Lemma: innovative\n",
      "Token: use, POS Tag: NN, Lemma: use\n",
      "Token: of, POS Tag: IN, Lemma: of\n",
      "Token: perspective, POS Tag: NN, Lemma: perspective\n",
      "Token: ., POS Tag: ., Lemma: .\n",
      "Token: The, POS Tag: DT, Lemma: The\n",
      "Token: Renaissance, POS Tag: NNP, Lemma: Renaissance\n",
      "Token: saw, POS Tag: VBD, Lemma: saw\n",
      "Token: a, POS Tag: DT, Lemma: a\n",
      "Token: resurgence, POS Tag: NN, Lemma: resurgence\n",
      "Token: of, POS Tag: IN, Lemma: of\n",
      "Token: interest, POS Tag: NN, Lemma: interest\n",
      "Token: in, POS Tag: IN, Lemma: in\n",
      "Token: classical, POS Tag: JJ, Lemma: classical\n",
      "Token: Greek, POS Tag: NNP, Lemma: Greek\n",
      "Token: and, POS Tag: CC, Lemma: and\n",
      "Token: Roman, POS Tag: NNP, Lemma: Roman\n",
      "Token: art, POS Tag: NN, Lemma: art\n",
      "Token: ,, POS Tag: ,, Lemma: ,\n",
      "Token: leading, POS Tag: VBG, Lemma: lead\n",
      "Token: to, POS Tag: TO, Lemma: to\n",
      "Token: the, POS Tag: DT, Lemma: the\n",
      "Token: development, POS Tag: NN, Lemma: development\n",
      "Token: of, POS Tag: IN, Lemma: of\n",
      "Token: new, POS Tag: JJ, Lemma: new\n",
      "Token: styles, POS Tag: NNS, Lemma: style\n",
      "Token: and, POS Tag: CC, Lemma: and\n",
      "Token: techniques, POS Tag: NNS, Lemma: technique\n",
      "Token: ., POS Tag: ., Lemma: .\n"
     ]
    }
   ],
   "source": [
    "analysis_result = morphological_analysis(paragraph)\n",
    "for token, pos_tag, lemma in analysis_result:\n",
    "    print(f\"Token: {token}, POS Tag: {pos_tag}, Lemma: {lemma}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['commercial_art', 'cyberart', 'diptych', 'genre', 'plastic_art', 'artificial_flower', 'grotesque', 'gem', 'treasure', 'triptych', 'dance', 'mosaic', 'kitsch', 'graphic_art', 'decoupage', 'work_of_art', 'sell', 'swim', 'drown', 'compact', 'pack', 'hoodoo', 'loiter', 'lounge', 'footle', 'lollygag', 'loaf', 'lallygag', 'hang_around', 'mess_about', 'tarry', 'linger', 'lurk', 'mill_about', 'mill_around', 'come_in_handy', 'want', 'need', 'require', 'lie', 'look', 'appear', 'seem', 'point', 'fall', 'come', 'sparkle', 'scintillate', 'coruscate', 'hum', 'buzz', 'seethe', 'deserve', 'merit', 'impend', 'rank', 'cohere', 'rage', 'litter', 'depend', 'look', 'draw', 'make_sense', 'add_up', 'consist', 'comprise', 'connect', 'breathe', 'pay', 'rate', 'stay', 'stay_on', 'continue', 'remain', 'count', 'specify', 'define', 'delineate', 'delimit', 'delimitate', 'lubricate', 'begin', 'start', 'wind', 'twist', 'curve', 'rest', 'buy', 'swim', 'deck', 'adorn', 'decorate', 'grace', 'embellish', 'beautify', 'stagnate', 'run_into', 'encounter', 'shine', 'abound', 'head', 'head_up', 'promise', 'distribute', 'disagree', 'disaccord', 'discord', 'figure', 'enter', 'bake', 'broil', 'iridesce', 'continue', 'cut', 'suffer', 'consist', 'prove', 'turn_out', 'turn_up', 'range', 'run', 'rut', 'test', 'osculate', 'squat', 'fall', 'wash', 'contain', 'take', 'hold', 'kill', 'clean', 'hang', 'act', 'represent', 'stagnate', 'stand', 'account_for', 'relate', 'interrelate', 'answer', 'feel', 'belong', 'end', 'terminate', 'stand', 'belong', 'seem', 'cost', 'be', 'balance', 'put_out', 'hold', 'gape', 'yawn', 'yaw', 'make', 'accept', 'take', 'mope', 'moon_around', 'moon_about', 'come_in_for', 'sell', 'beat', 'subtend', 'delimit', 'hail', 'come', 'tend', 'be_given', 'lean', 'incline', 'run', 'gravitate', 'jumble', 'mingle', 'be_well', 'stay', 'remain', 'rest', 'let_go', 'press', 'account', 'stand_by', 'stick_by', 'stick', 'adhere', 'count', 'matter', 'weigh', 'translate', 'retard', 'suck', 'cut_across', 'belong', 'swing', 'suffer', 'hurt', 'owe', 'remain', 'lend', 'shine', 'fit', 'cover', 'belong', 'seethe', 'boil', 'begin', 'sell', 'transplant', 'object', 'recognize', 'confuse', 'throw', 'fox', 'befuddle', 'fuddle', 'bedevil', 'confound', 'discombobulate', 'compare', 'trim', 'incarnate', 'body_forth', 'embody', 'substantiate', 'suit', 'appear', 'seem', 'go', 'contain', 'total', 'number', 'add_up', 'come', 'amount', 'diverge', 'measure', 'underlie', 'stink', 'stick', 'work', 'run', 'go', 'rise', 'modernist', 'Indiana', 'Robert_Indiana', 'musician', 'minimalist', 'etcher', 'classic', 'constructivist', 'draftsman', 'drawer', 'painter', 'decorator', 'ornamentalist', 'pyrographer', 'expressionist', 'classicist', 'symbolist', 'Pre-Raphaelite', 'stylist', 'photographer', 'lensman', 'surrealist', 'illustrator', 'sculptor', 'sculpturer', 'carver', 'statue_maker', 'maestro', 'master', 'printmaker', 'graphic_artist', 'romanticist', 'romantic', 'film-make', 'produce', 'bring_about', 'give_rise', 'create_verbally', 'grind', 'distill', 'extract', 'distil', 're-create', 'construct', 'build', 'make', 'establish', 'give', 'assemble', 'piece', 'put_together', 'set_up', 'tack', 'tack_together', 'choreograph', 'raise', 'lay_down', 'establish', 'make', 'twine', 'short-circuit', 'short', 'derive', 'educe', 'realize', 'realise', 'actualize', 'actualise', 'substantiate', 'recreate', 'scrape', 'give', 'yield', 'incorporate', 'bring', 'work', 'play', 'wreak', 'make_for', 'cleave', 'film', 'raise', 'conjure', 'conjure_up', 'invoke', 'evoke', 'stir', 'call_down', 'arouse', 'bring_up', 'put_forward', 'call_forth', 'cut', 'reproduce', 'procreate', 'multiply', 'compose', 'write', 'create_from_raw_material', 'create_from_raw_stuff', 'prepare', 'blast', 'shell', 'track', 'arouse', 'elicit', 'enkindle', 'kindle', 'evoke', 'fire', 'raise', 'provoke', 'froth', 'spume', 'suds', 'direct', 'generate', 'bring_forth', 'form', 'organize', 'organise', 'produce', 'bring_forth', 'style', 'institute', 'bring', 'build', 'establish', 'regenerate', 'put_on', 'turn_in', 'strike', 'puncture', 'cut', 'beat', 'chop', 'create_by_mental_act', 'create_mentally', 'offset', 'press', 'copy', 're-create', 'beget', 'get', 'engender', 'father', 'mother', 'sire', 'generate', 'bring_forth', 'bear', 'turn_out', 'originate', 'initiate', 'start', 'cause', 'do', 'make', 'create', 'make', 'clear', 'manufacture', 'mission', 'missionary_work', 'subbing', 'substituting', 'shining', 'polishing', 'housework', 'housekeeping', 'undertaking', 'project', 'task', 'labor', 'operation', 'procedure', 'ironing', 'job', 'duty', 'timework', 'loose_end', 'unfinished_business', 'logging', 'paperwork', 'service', 'action', 'coursework', 'nightwork', 'labor', 'labour', 'toil', 'care', 'attention', 'aid', 'tending', 'spadework', 'welfare_work', 'social_service', 'housewifery', 'investigation', 'investigating', 'job', 'busywork', 'make-work', 'wash', 'washing', 'lavation', 'heavy_lifting', 'bonding', 'emulation', 'photomechanics', 'immunofluorescence', 'antialiasing', 'simulation', 'computer_simulation', 'Benday_process', 'play', 'exploitation', 'development', 'recycling', 'application', 'practical_application', 'practice', 'misuse', 'abuse', 'vanguard', 'forefront', 'cutting_edge', 'light', 'Weltanschauung', 'world_view', 'sight', 'straddle', \"bird's_eye_view\", 'panoramic_view', 'futurism', 'paradigm', 'regeneration', 'rebirth', 'Renaissance', 'Renascence', 'resuscitation', 'resurrection', 'enthusiasm', 'concern', 'fugue', 'opera', 'chamber_music', 'sonata', 'concerto', 'cantata', 'oratorio', 'rondo', 'rondeau', 'Ancient_Greek', 'Koine', 'Modern_Greek', 'New_Greek', 'Late_Greek', 'Medieval_Greek', 'Middle_Greek', 'Byzantine_Greek', 'commercial_art', 'cyberart', 'diptych', 'genre', 'plastic_art', 'artificial_flower', 'grotesque', 'gem', 'treasure', 'triptych', 'dance', 'mosaic', 'kitsch', 'graphic_art', 'decoupage', 'work_of_art', 'elaboration', 'working_out', 'product_development', 'broadening', 'advancement', 'progress', 'artistic_style', 'idiom', 'setup', 'form', 'life_style', 'life-style', 'lifestyle', 'modus_vivendi', 'response', 'fit', 'drape', 'touch', 'signature', 'wise', 'bonding', 'emulation', 'photomechanics', 'immunofluorescence', 'antialiasing', 'simulation', 'computer_simulation', 'Benday_process']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "tokens = nltk.word_tokenize(paragraph)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmas = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "synsets = [wordnet.synsets(lemma) for lemma in lemmas]\n",
    "\n",
    "hyponyms = []\n",
    "for synset in synsets:\n",
    "    if synset:\n",
    "        hyponyms.extend(synset[0].hyponyms())\n",
    "\n",
    "generated_words = []\n",
    "for hyponym in hyponyms:\n",
    "    generated_words.extend([lemma.name() for lemma in hyponym.lemmas()])\n",
    "\n",
    "print(generated_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
